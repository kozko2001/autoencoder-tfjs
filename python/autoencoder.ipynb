{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcoscolla/tmp/autoencoder/python/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize between 0..1\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "autoencoder = load_model('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(2, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "## encoded dim is 4x4x2\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=/tmp/autoencoder &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jcoscolla/tmp/autoencoder/python/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 38s 641us/step - loss: 0.2869 - val_loss: 0.2233\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 38s 640us/step - loss: 0.2049 - val_loss: 0.1842\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 39s 642us/step - loss: 0.1812 - val_loss: 0.1754\n"
     ]
    }
   ],
   "source": [
    "## Compile\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "## Train\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=3,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')],\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "autoencoder.save('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some images \n",
    "\n",
    "First row is the original\n",
    "Second row is the auto-decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcoscolla/tmp/autoencoder/python/venv/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 19 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = x_test[1]\n",
    "\n",
    "image = np.expand_dims(image, axis=0)\n",
    "decoded = autoencoder.predict(image)\n",
    "#encoded_img = encoder.predict(image)\n",
    "\n",
    "#print(encoded_img)\n",
    "\n",
    "def show_image(image, shape = (28,28)):\n",
    "    plt.imshow(image.reshape(shape[0], shape[1]))\n",
    "\n",
    "show_image(image)\n",
    "show_image(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(autoencoder, 'model/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
